{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "Import Dependencies and Libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.28.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1623514446274
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Workspace and Experiment\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'titanic-survival-prediction'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "project_folder = './automl-project'\n",
        "\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "personal-workspace\n",
            "personal\n",
            "eastus2\n",
            "8fb18662-8aa6-4db6-8a37-65c1a334f920\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1623514449066
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Compute Target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# NOTE: update the cluster name to match the existing cluster\n",
        "# Choose a name for your CPU cluster\n",
        "amlcompute_cluster_name = \"aml-compute\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=1)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "#compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "#compute_target.get_status()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623514459699
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "This dataset contains the actual information about titanic passengers and whether or not each passenger survived. Obtained from https://data.world/nrippner/titanic-disaster-dataset\n",
        "\n",
        "Features:\n",
        "\n",
        "survived - Survival (0 = No; 1 = Yes)\n",
        "\n",
        "\n",
        "class - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "\n",
        "\n",
        "sex - Sex\n",
        "\n",
        "\n",
        "age - Age\n",
        "\n",
        "\n",
        "sibsp - Number of Siblings/Spouses Aboard\n",
        "\n",
        "\n",
        "parch - Number of Parents/Children Aboard\n",
        "\n",
        "\n",
        "fare - Passenger Fare\n",
        "\n",
        "\n",
        "cabin - Cabin\n",
        "\n",
        "\n",
        "embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name='titanic-survival')\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "   pclass  survived     sex   age  sibsp  parch   fare    cabin embarked\n0    1.00      1.00  female 29.00   0.00   0.00 211.34       B5        S\n1    1.00      1.00    male  0.92   1.00   2.00 151.55  C22 C26        S\n2    1.00      0.00  female  2.00   1.00   2.00 151.55  C22 C26        S\n3    1.00      0.00    male 30.00   1.00   2.00 151.55  C22 C26        S\n4    1.00      0.00  female 25.00   1.00   2.00 151.55  C22 C26        S",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>female</td>\n      <td>29.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>211.34</td>\n      <td>B5</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>male</td>\n      <td>0.92</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>151.55</td>\n      <td>C22 C26</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>female</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>151.55</td>\n      <td>C22 C26</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>male</td>\n      <td>30.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>151.55</td>\n      <td>C22 C26</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>female</td>\n      <td>25.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>151.55</td>\n      <td>C22 C26</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623535928380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "We will be setting the experiment to be timed out at 20 minutes to cut down on runtime and cost. \n",
        "Since the maximum number of nodes for the compute cluster is 1, the maximum number of concurrent iterations is set to 1. The primary metric is set to a weighted AUC since this is a classification problem with imbalanced classes. \n",
        "The target column is called 'survived'. Early stopping is enabled for time and cost efficiency. Featurization is set to auto which is default."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 1,\n",
        "    \"primary_metric\" : 'AUC_weighted'\n",
        "}\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data=dataset,\n",
        "                             label_column_name=\"survived\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1623514698235
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting remote run.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>titanic-survival-prediction</td><td>AutoML_e2f75cf8-aae1-4744-b7a0-46f65cd40677</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_e2f75cf8-aae1-4744-b7a0-46f65cd40677?wsid=/subscriptions/8fb18662-8aa6-4db6-8a37-65c1a334f920/resourcegroups/personal/workspaces/personal-workspace&amp;tid=41f83608-ac15-4410-bf59-af30a0f8cb83\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1623514707750
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        " In the cell below, use the `RunDetails` widget to show the different experiments.\n",
        "\n",
        " Note: For some reason when I run the widget, I get network issues and am unable to save my notebook. I have to reload my notebook. Therefore I did not run this cell in this notebook as I wanted to go ahead with the subsequent cells. \n",
        " \n",
        " I did however run it separately and have displayed the results in the project's readme file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(remote_run).show()\n",
        "remote_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "Get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "best_run, fitted_model = remote_run.get_output()\n",
        "print(best_run,'\\n')\n",
        "print(fitted_model,'\\n')\n",
        "print(best_run.get_metrics(),'\\n')\n",
        "print(best_run.get_file_names(),'\\n')\n",
        "joblib.dump(fitted_model, './automl-project/best_automl_model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
            "WARNING:root:The consistency in the result may not be guaranteed.\n",
            "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-automl-runtime, training version:1.30.0, current version:1.28.0.post2\n",
            "Package:azureml-core, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-defaults, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-interpret, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-mlflow, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-pipeline-core, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-telemetry, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-train-automl-client, training version:1.30.0, current version:1.28.0\n",
            "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.28.0\n",
            "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: titanic-survival-prediction,\n",
            "Id: AutoML_d1b014e0-0b3e-4350-bba6-843170b7786e_21,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed) \n",
            "\n",
            "Pipeline(memory=None,\n",
            "         steps=[('datatransformer',\n",
            "                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...\n",
            "), random_state=0, reg_alpha=1.1458333333333335, reg_lambda=1.3541666666666667, subsample=0.6, tree_method='auto'))], verbose=False)), ('17', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features='log2', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1, oob_score=True, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('9', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features=0.1, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.15052631578947367, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('8', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=0.05, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.10368421052631578, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('14', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='log2', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.07692307692307693, 0.15384615384615385, 0.15384615384615385, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.15384615384615385, 0.15384615384615385, 0.07692307692307693]))],\n",
            "         verbose=False)\n",
            "Y_transformer(['LabelEncoder', LabelEncoder()]) \n",
            "\n",
            "{'f1_score_macro': 0.7904525254894801, 'AUC_macro': 0.866489631787033, 'precision_score_weighted': 0.8124775256598605, 'AUC_weighted': 0.866489631787033, 'average_precision_score_micro': 0.8630269405420762, 'weighted_accuracy': 0.8370511151228053, 'AUC_micro': 0.8777829445509552, 'balanced_accuracy': 0.7808551094813295, 'f1_score_micro': 0.810520017634833, 'norm_macro_recall': 0.5617102189626589, 'average_precision_score_weighted': 0.8658686570443779, 'precision_score_micro': 0.810520017634833, 'average_precision_score_macro': 0.8593150769589532, 'f1_score_weighted': 0.8057657426645345, 'recall_score_weighted': 0.810520017634833, 'precision_score_macro': 0.8130866434686842, 'accuracy': 0.810520017634833, 'recall_score_micro': 0.810520017634833, 'recall_score_macro': 0.7808551094813295, 'matthews_correlation': 0.5929720062539943, 'log_loss': 0.5092850353939743, 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_d1b014e0-0b3e-4350-bba6-843170b7786e_21/accuracy_table', 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_d1b014e0-0b3e-4350-bba6-843170b7786e_21/confusion_matrix'} \n",
            "\n",
            "['accuracy_table', 'automl_driver.py', 'azureml-logs/55_azureml-execution-tvmps_a0ce007439380bcaf6c427e2d7f1d6b06643e320f7956f007f12b88eac0eb93a_d.txt', 'azureml-logs/65_job_prep-tvmps_a0ce007439380bcaf6c427e2d7f1d6b06643e320f7956f007f12b88eac0eb93a_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_a0ce007439380bcaf6c427e2d7f1d6b06643e320f7956f007f12b88eac0eb93a_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'confusion_matrix', 'explanation/3255d274/classes.interpret.json', 'explanation/3255d274/eval_data_viz.interpret.json', 'explanation/3255d274/expected_values.interpret.json', 'explanation/3255d274/features.interpret.json', 'explanation/3255d274/global_names/0.interpret.json', 'explanation/3255d274/global_rank/0.interpret.json', 'explanation/3255d274/global_values/0.interpret.json', 'explanation/3255d274/local_importance_values.interpret.json', 'explanation/3255d274/per_class_names/0.interpret.json', 'explanation/3255d274/per_class_rank/0.interpret.json', 'explanation/3255d274/per_class_values/0.interpret.json', 'explanation/3255d274/rich_metadata.interpret.json', 'explanation/3255d274/true_ys_viz.interpret.json', 'explanation/3255d274/visualization_dict.interpret.json', 'explanation/a386c41e/classes.interpret.json', 'explanation/a386c41e/expected_values.interpret.json', 'explanation/a386c41e/features.interpret.json', 'explanation/a386c41e/global_names/0.interpret.json', 'explanation/a386c41e/global_rank/0.interpret.json', 'explanation/a386c41e/global_values/0.interpret.json', 'explanation/a386c41e/local_importance_values.interpret.json', 'explanation/a386c41e/per_class_names/0.interpret.json', 'explanation/a386c41e/per_class_rank/0.interpret.json', 'explanation/a386c41e/per_class_values/0.interpret.json', 'explanation/a386c41e/rich_metadata.interpret.json', 'explanation/a386c41e/true_ys_viz.interpret.json', 'explanation/a386c41e/visualization_dict.interpret.json', 'explanation/a386c41e/ys_pred_proba_viz.interpret.json', 'explanation/a386c41e/ys_pred_viz.interpret.json', 'logs/azureml/109_azureml.log', 'logs/azureml/azureml_automl.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/conda_env_v_1_0_0.yml', 'outputs/env_dependencies.json', 'outputs/internal_cross_validated_models.pkl', 'outputs/model.pkl', 'outputs/pipeline_graph.json', 'outputs/scoring_file_v_1_0_0.py', 'outputs/scoring_file_v_2_0_0.py'] \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "['./automl-project/best_automl_model.joblib']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1623532223987
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the best model\n",
        "\n",
        "joblib.load('./automl-project/best_automl_model.joblib')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "PipelineWithYTransformations(Pipeline={'memory': None,\n                                       'steps': [('datatransformer',\n                                                  DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mn...\n), random_state=0, reg_alpha=1.1458333333333335, reg_lambda=1.3541666666666667, subsample=0.6, tree_method='auto'))], verbose=False)), ('17', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features='log2', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1, oob_score=True, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('9', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced', criterion='gini', max_depth=None, max_features=0.1, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.15052631578947367, min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('8', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features=0.05, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.10368421052631578, min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('14', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='log2', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=0.01, min_samples_split=0.01, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False))], flatten_transform=None, weights=[0.07692307692307693, 0.15384615384615385, 0.15384615384615385, 0.07692307692307693, 0.07692307692307693, 0.07692307692307693, 0.15384615384615385, 0.15384615384615385, 0.07692307692307693]))],\n                                       'verbose': False},\n                             y_transformer={},\n                             y_transformer_name='LabelEncoder')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1623532344219
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the environment of the best model\n",
        "best_run.download_file('outputs/conda_env_v_1_0_0.yml','my_env.yml')"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623532556146
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the scoring script which will be used for deployment \n",
        "best_run.download_file('outputs/scoring_file_v_2_0_0.py','score.py')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623532646553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "In the cells below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Register best model\n",
        "model = best_run.register_model(model_name='best_automl_model',\n",
        "                           model_path='outputs/model.pkl')\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_automl_model\tbest_automl_model:3\t3\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1623532739343
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model environment\n",
        "from azureml.core import Environment\n",
        "env = Environment.from_conda_specification(name='myenv', file_path='./my_env.yml')"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623532845793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy best model as an ACI webservice\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.model import Model\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "deployment_config = AciWebservice.deploy_configuration(auth_enabled=True, enable_app_insights=True)\n",
        "service = Model.deploy(ws, \"automl-deploy\", [model], inference_config, deployment_config)\n",
        "service.wait_for_deployment(show_output = True)\n",
        "print(service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-06-12 21:26:22+00:00 Creating Container Registry if not exists..\n",
            "2021-06-12 21:26:32+00:00 Registering the environment.\n",
            "2021-06-12 21:26:33+00:00 Building image..\n",
            "2021-06-12 21:41:35+00:00 Generating deployment configuration.\n",
            "2021-06-12 21:41:36+00:00 Submitting deployment to compute..\n",
            "2021-06-12 21:41:40+00:00 Checking the status of deployment automl-deploy..\n",
            "2021-06-12 21:45:05+00:00 Checking the status of inference endpoint automl-deploy.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Healthy\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623534349381
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consume Deployed Model\n",
        "In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "#Request data goes here\n",
        "data = {\n",
        "    \"Inputs\": {\n",
        "        \"data\":\n",
        "        [\n",
        "            {\n",
        "                'pclass': 1,\n",
        "                'sex': \"female\",\n",
        "                'age': 29,\n",
        "                'sibsp': 0,\n",
        "                'parch': 0,\n",
        "                'fare': 211,\n",
        "                'cabin': \"B5\",\n",
        "                'embarked': \"S\",\n",
        "            }, \n",
        "            {\n",
        "                'pclass': 3,\n",
        "                'sex': \"male\",\n",
        "                'age': 29,\n",
        "                'sibsp': 1,\n",
        "                'parch': 1,\n",
        "                'fare': 211,\n",
        "                'cabin': \"B5\",\n",
        "                'embarked': \"S\",\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "}\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'http://3abbe71b-d53e-4559-a598-5d0213b50c4c.eastus2.azurecontainer.io/score'\n",
        "\n",
        "primary, secondary = service.get_keys()\n",
        "api_key = primary\n",
        "\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'[1.0, 0.0]'\n"
          ]
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1623538243064
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View Logs and Clean Up\n",
        "In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-06-12T21:44:54,540977087+00:00 - rsyslog/run \n",
            "2021-06-12T21:44:54,640395887+00:00 - gunicorn/run \n",
            "2021-06-12T21:44:54,640394087+00:00 - iot-server/run \n",
            "2021-06-12T21:44:54,741701111+00:00 - nginx/run \n",
            "rsyslogd: /azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-06-12T21:44:57,340704960+00:00 - iot-server/finish 1 0\n",
            "2021-06-12T21:44:57,343196792+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 20.1.0\n",
            "Listening at: http://127.0.0.1:31311 (13)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 42\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Generating new fontManager, this may take some time...\n",
            "Initializing logger\n",
            "2021-06-12 21:45:13,346 | root | INFO | Starting up app insights client\n",
            "2021-06-12 21:45:13,347 | root | INFO | Starting up request id generator\n",
            "2021-06-12 21:45:13,347 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 21:45:13,347 | root | INFO | Invoking user's init function\n",
            "2021-06-12 21:45:41,944 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 21:45:43,343 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 21:45:43,444 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 21:45:43,444 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 21:45:43,539 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 21:45:48,195 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:21:45:48 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 21:45:49,206 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:21:45:49 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 21:47:06,547 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:21:47:06 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:10:09,393 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:10:09,396 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:10:09,441 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:10:09,442 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:10:09 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:10:09,549 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:10:09,642 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:10:09,643 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:10:09,643 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:10:09 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:10:10,655 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:10:10,658 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:10:10,659 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:10:10,659 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:10:10 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:10:12,669 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:10:12,672 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:10:12,673 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:10:12,673 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:10:12 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 42)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 67\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:11:27,147 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:11:27,148 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:11:27,148 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:11:27,148 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:11:55,149 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:11:56,439 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:11:56,449 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:11:56,449 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:11:56,450 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:13:06,799 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:13:06,800 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:13:06,803 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:13:06,803 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:06 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:13:06,946 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:13:07,039 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:13:07,041 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:13:07,041 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:07 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:13:08,048 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:13:08,049 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:13:08,050 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:13:08,051 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:08 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:13:10,059 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:13:10,059 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:13:10,060 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:13:10,060 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:10 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:13:24,587 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:24 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:13:46,843 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:13:46 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:14:00,628 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:14:00 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 67)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 90\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:14:24,749 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:14:24,749 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:14:24,750 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:14:24,839 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:14:53,146 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:14:54,443 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:14:54,545 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:14:54,546 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:14:54,640 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:14:54,646 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:14:54 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:16:08,485 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:16:08,486 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:16:10,246 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:16:10 +0000] \"POST /score?verbose=true HTTP/1.0\" 200 5 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:17:01,012 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:17:01,013 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:17:01,017 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:17:01,041 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:17:01 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:17:01,146 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:17:01,147 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:17:01,148 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:17:01,148 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:17:01 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:17:02,249 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:17:02,249 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:17:02,250 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:17:02,251 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:17:02 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:17:04,261 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:17:04,261 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:17:04,263 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:17:04,263 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:17:04 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 90)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 113\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:18:19,346 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:18:19,346 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:18:19,346 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:18:19,347 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:18:47,743 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:18:49,042 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:18:49,149 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:18:49,149 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:18:49,239 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:18:49,244 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:18:49,245 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:18:49,341 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:18:49,341 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:18:49 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:18:49,641 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:18:49,641 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:18:49,643 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:18:49,643 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:18:49 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:18:50,651 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:18:50,651 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:18:50,652 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:18:50,653 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:18:50 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:18:52,659 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:18:52,660 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:18:52,661 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:18:52,661 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:18:52 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:19:43,807 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:19:43 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 113)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 134\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:20:07,444 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:20:07,445 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:20:07,445 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:20:07,445 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:20:35,849 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:20:37,339 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:20:37,439 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:20:37,439 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:20:37,441 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:24:16,772 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:24:16,775 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:24:16,776 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:24:16 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:24:16,842 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:24:16,843 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:24:16,843 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:24:16 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:24:17,852 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:24:17,852 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:24:17,853 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:24:17 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:24:19,863 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:24:19,864 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:24:19,864 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:24:19 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:26:45,677 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:26:45,678 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:26:45,678 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:26:45 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:26:45,687 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:26:45,687 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:26:45,687 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:26:45 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:26:46,695 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:26:46,696 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:26:46,696 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:26:46 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:26:48,703 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:26:48,704 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 74, in get_json\n",
            "    rv = json.loads(data)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/json/__init__.py\", line 236, in loads\n",
            "    return _json.loads(s, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/__init__.py\", line 367, in loads\n",
            "    return cls(**kw).decode(s)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 339, in decode\n",
            "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/json/decoder.py\", line 357, in raw_decode\n",
            "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
            "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 37, in score_realtime\n",
            "    service_input = request.get_json()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 82, in get_json\n",
            "    rv = self.on_json_loading_failed(e)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/wrappers.py\", line 108, in on_json_loading_failed\n",
            "    raise BadRequest()\n",
            "werkzeug.exceptions.BadRequest: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.\n",
            "\n",
            "2021-06-12 22:26:48,704 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:26:48 +0000] \"POST /score HTTP/1.0\" 500 2067 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:35:18,528 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:35:18,529 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:35:18,532 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:35:18,540 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:35:18 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:35:18,643 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:35:18,643 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:35:18,645 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:35:18,645 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:35:18 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:35:19,654 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:35:19,655 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:35:19,656 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:35:19,656 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:35:19 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:35:21,663 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:35:21,663 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:35:21,664 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 55, in decorator_input\n",
            "    args[param_position] = _deserialize_input_argument(args[param_position], param_type, param_name)\n",
            "IndexError: list index out of range\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:35:21,665 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:35:21 +0000] \"POST /score HTTP/1.0\" 500 23 \"-\" \"python-requests/2.25.1\"\n",
            "2021-06-12 22:36:00,401 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:36:00 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 134)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 157\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:36:35,948 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:36:35,948 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:36:35,948 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:36:35,948 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:37:04,041 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:37:05,339 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:37:05,443 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:37:05,443 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:37:05,445 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:37:05,449 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:37:05 +0000] \"GET /swagger.json HTTP/1.0\" 200 2690 \"-\" \"Go-http-client/1.1\"\n",
            "2021-06-12 22:39:23,699 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:39:23,700 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:39:23,942 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 61, in decorator_input\n",
            "    return user_run(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 88, in decorator_input\n",
            "    return user_run(*args, **kwargs)\n",
            "TypeError: run() got an unexpected keyword argument 'GlobalParameters'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:39:23,943 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:39:23 +0000] \"POST /score HTTP/1.0\" 500 59 \"-\" \"Python-urllib/3.6\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 157)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 178\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:40:38,541 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:40:38,542 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:40:38,542 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:40:38,542 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:41:06,642 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:41:07,939 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:41:08,040 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:41:08,040 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:41:08,042 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:41:08,141 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:41:08,142 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:41:08,448 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
            "    response = invoke_user_with_timer(service_input, request_headers)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
            "    result = user_main.run(**params)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 61, in decorator_input\n",
            "    return user_run(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/inference_schema/schema_decorators.py\", line 88, in decorator_input\n",
            "    return user_run(*args, **kwargs)\n",
            "TypeError: run() got an unexpected keyword argument 'GlobalParameters'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
            "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
            "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
            "    raise RunFunctionException(str(exc))\n",
            "run_function_exception.RunFunctionException\n",
            "\n",
            "2021-06-12 22:41:08,448 | root | INFO | 500\n",
            "127.0.0.1 - - [12/Jun/2021:22:41:08 +0000] \"POST /score HTTP/1.0\" 500 59 \"-\" \"Python-urllib/3.6\"\n",
            "Exception in worker process\n",
            "Traceback (most recent call last):\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 589, in spawn_worker\n",
            "    worker.init_process()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 142, in init_process\n",
            "    self.run()\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 125, in run\n",
            "    self.run_for_one(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 84, in run_for_one\n",
            "    self.wait(timeout)\n",
            "  File \"/azureml-envs/azureml_844426f9a15fdc0e079dc03e91d975e1/lib/python3.6/site-packages/gunicorn/workers/sync.py\", line 36, in wait\n",
            "    ret = select.select(self.wait_fds, [], [], timeout)\n",
            "  File \"/var/azureml-server/routes_common.py\", line 162, in alarm_handler\n",
            "    raise TimeoutException(error_message)\n",
            "timeout_exception.TimeoutException\n",
            "Worker exiting (pid: 178)\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 198\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Initializing logger\n",
            "2021-06-12 22:42:23,049 | root | INFO | Starting up app insights client\n",
            "2021-06-12 22:42:23,050 | root | INFO | Starting up request id generator\n",
            "2021-06-12 22:42:23,050 | root | INFO | Starting up app insight hooks\n",
            "2021-06-12 22:42:23,139 | root | INFO | Invoking user's init function\n",
            "2021-06-12 22:42:51,345 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
            "2021-06-12 22:42:52,739 | root | INFO | Users's init has completed successfully\n",
            "2021-06-12 22:42:52,750 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-06-12 22:42:52,839 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-06-12 22:42:52,841 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-06-12 22:42:52,940 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:42:52,940 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:42:54,845 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:42:55 +0000] \"POST /score HTTP/1.0\" 200 5 \"-\" \"Python-urllib/3.6\"\n",
            "2021-06-12 22:44:49,814 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:44:49,814 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:44:50,948 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:44:51 +0000] \"POST /score HTTP/1.0\" 200 5 \"-\" \"Python-urllib/3.6\"\n",
            "2021-06-12 22:50:40,937 | root | INFO | Validation Request Content-Type\n",
            "2021-06-12 22:50:40,938 | root | INFO | Scoring Timer is set to 60.0 seconds\n",
            "2021-06-12 22:50:43,044 | root | INFO | 200\n",
            "127.0.0.1 - - [12/Jun/2021:22:50:43 +0000] \"POST /score HTTP/1.0\" 200 10 \"-\" \"Python-urllib/3.6\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 56,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623538257942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete deployed webservice\n",
        "service.delete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No service with name automl-deploy found to delete.\n"
          ]
        }
      ],
      "execution_count": 61,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623560555006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete compute cluster\n",
        "compute_target.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}